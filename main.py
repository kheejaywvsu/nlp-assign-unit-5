from utils.fetch_data import fetch_wikipedia_docs
from term_document_matrix import build_matrices
from cosine_similarity import compute_similarity
from word2vec_classifier import train_classifier

# Configuration
TOPICS = [
    "Python (programming language)",
    "JavaScript",
    "Data science",
    "Machine learning",
    "Deep learning"
]

def main():
    print("ğŸš€ Starting Document Analysis Pipeline\n")

    try:
        # Phase 1: Data Acquisition & Preprocessing
        print("ğŸ” Fetching Wikipedia documents...")
        documents, titles = fetch_wikipedia_docs(TOPICS)
        print(f"âœ… Retrieved {len(documents)} documents\n")

        # Phase 2: Term-Document Analysis
        print("ğŸ“Š Building term-document matrices...")
        raw_df, tfidf_df = build_matrices(documents, titles)

        # Phase 3: Similarity Analysis
        print("\nğŸ“ Calculating document similarities...")
        similarity_df, (doc1, doc2, score) = compute_similarity(tfidf_df.values, titles)

        # Phase 4: Embedding & Classification
        print("\nğŸ¤– Training Word2Vec classifier...")
        accuracy = train_classifier(documents, titles)

        # Final Results
        print("\nğŸ“Š Pipeline Results:")
        print(f"â¤ Most Similar Documents: '{doc1}' & '{doc2}' (Score: {score:.2f})")
        print(f"â¤ Classification Accuracy: {accuracy:.2f}")

    except Exception as e:
        print(f"\nâŒ Pipeline Failed: {str(e)}")
        raise

if __name__ == "__main__":
    main()
    print("\nğŸ‰ Analysis Complete!")
